{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following function of the \"ground truth\", and a few sample data points we will use for regression. The example is by Mathieu Blondel & Jake Vanderplas ([source](http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: x * np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, n = 1000, 10\n",
    "domain = np.linspace(0, 10, N)\n",
    "x_sample = np.sort(np.random.choice(domain, n))\n",
    "y_sample = func(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAD8CAYAAAA/pA4OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n76Xrm7oG5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119c06d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.plot(domain, func(domain), label=\"ground truth\")\n",
    "f = plt.scatter(x_sample, func(x_sample), label=\"samples\")\n",
    "f = plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously linear regression won't bring you far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "model = LinearRegression().fit(X, y_sample)\n",
    "print \"R2 =\", model.score(X, y_sample)\n",
    "f = plt.plot(domain, func(domain), label=\"ground truth\")\n",
    "f = plt.scatter(x_sample, func(x_sample), label=\"samples\")\n",
    "f = plt.plot([0, 10], [model.intercept_, model.intercept_ + 10 * model.coef_[0]], label=\"linear regression\")\n",
    "f = plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a few polynomial regressions to fit the given sample data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "# f = plt.plot(x, func(x), label=\"ground truth\", alpha=.4)\n",
    "f = plt.scatter(x_sample, func(x_sample), label=\"samples\")\n",
    "\n",
    "degree = 2\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression()).fit(X, y_sample)\n",
    "y_pred = model.predict(np.array([domain]).T)\n",
    "plt.plot(domain, y_pred, label=\"degree %d\" % degree)\n",
    "\n",
    "f = plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's actually a result from algebra that you can fit *any* finite set of data points with a polynomial. \n",
    "- In fact, for any set of $n$ data points, there exists a polynomial of degree $n$ that goes right through them.\n",
    "- This is great if you'd want to approximate your data arbitrarily closely.\n",
    "- It's not great if you're afraid of overfitting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to find a model behind some data, which also contains some arbitrary noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = lambda x: 1 + .1 * (x - 4) ** 2 + 4 * np.random.random(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, n = 1000, 30\n",
    "domain = np.linspace(0, 15, N)\n",
    "x_sample = np.linspace(0, 15, n)\n",
    "y_sample = func(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.scatter(x_sample, func(x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously you could fit this noise by an arbitrarily complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T\n",
    "f = plt.scatter(x_sample, func(x_sample))\n",
    "\n",
    "for degree in [3, 8, 13]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression()).fit(X, y_sample)\n",
    "    y_pred = model.predict(np.array([domain]).T)\n",
    "    plt.plot(domain, y_pred, alpha=.5, label=\"deg %d (R2 %.2f)\" % (degree, model.score(X, y_sample)))\n",
    "\n",
    "f = plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that that is obviously not what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.scatter(x_sample, func(x_sample), label=\"samples\")\n",
    "for degree in [1, 2, 3, 4, 5]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    # Compute a few R2 scores and print average performance\n",
    "    scores = []\n",
    "    for k in xrange(15):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_sample, train_size=.7)\n",
    "        scores.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "    print \"For degree\", degree, \", R2 =\", np.mean(scores)\n",
    "    # Take last model to plot predictions\n",
    "    y_pred = model.predict(np.array([domain]).T)\n",
    "    plt.plot(domain, y_pred, alpha=.5, label=\"deg %d (R2 %.2f)\" % (degree, model.score(X_test, y_test)))\n",
    "\n",
    "    f = plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a second or third degree polynomial performs better than a fifth one on unseen data, which makes sense, since that's how we generated the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the different models once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_performance(test_model):\n",
    "    scores = {'overfit': {}, 'cv': {}}\n",
    "    for degree in xrange(0, 30):\n",
    "        model = make_pipeline(PolynomialFeatures(degree), test_model)    \n",
    "        scores['overfit'][degree] = model.fit(X, y_sample).score(X, y_sample)\n",
    "        cv_scores = []\n",
    "        for k in xrange(15):  # Compute a few R2 scores and print average performance\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y_sample, train_size=.7)\n",
    "            cv_scores.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "        scores['cv'][degree] = np.mean(cv_scores)\n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = analyze_performance(LinearRegression())\n",
    "f = scores.plot(ylim=(-.05,1.05))\n",
    "f = plt.title(\"Best cv performance at degree %d\" % scores.cv.argmax()), plt.xlabel('degree'), plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "If your model is very complex (i.e., lots of features, possibly a polynomial fit, etc.), you need to worry more about overfitting.\n",
    "- You'll need regularization when your model is complex, which happens when you have very few data or many features.\n",
    "- The example below uses the same dataset as above, but with fewer samples, and a relatively high degree model.\n",
    "- We'll fit the (unregularized) `LinearRegression`, as well as the (regularized) `Ridge` and `Lasso` model.\n",
    "  - Lasso regression imposes an L1 prior on the coefficient, causing many coeffiecients to be zero.\n",
    "  - Ridge regression imposes an L2 prior on the coefficient, causing outliers to be less likely, and coeffiecients to be small across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_small_sample = x_sample[::4]\n",
    "y_small_sample = func(x_small_sample)\n",
    "\n",
    "degree, alpha = 4, 10\n",
    "\n",
    "X = np.array([x_small_sample]).T\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 4))\n",
    "for no, my_model in enumerate([LinearRegression(), Ridge(alpha=alpha), Lasso(alpha=alpha)]):    \n",
    "    model = make_pipeline(PolynomialFeatures(degree), my_model)    \n",
    "    r2, MSE = [], []\n",
    "    for k in xrange(100):  # Fit a few times the model to different training sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_small_sample, train_size=.7)\n",
    "        r2.append(model.fit(X_train, y_train).score(X_test, y_test))\n",
    "        y_pred = model.predict(np.array([domain]).T)\n",
    "        axes[no].plot(domain, y_pred, alpha=.3)\n",
    "        y_pred_sample = model.predict(np.array([x_small_sample]).T)\n",
    "        MSE.append(np.square(y_pred_sample - y_small_sample).sum())\n",
    "    axes[no].scatter(x_small_sample, y_small_sample, s=70)\n",
    "    axes[no].set_title(\"%s (R2 %.2f, MSE %3d)\" % (my_model.__class__.__name__, np.mean(scores)[1], np.mean(MSE)))\n",
    "    axes[no].set_xlim(-.2, max(domain)), axes[no].set_ylim(-1, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indeed, the unregularized `LinearRegression` leads to a model that is too complex and tries to fit the noise. \n",
    "- Note the differences in the (averaged) mean square error, or MSE, as well the complexity in the plots\n",
    "- Note that the $R^2$ metric is not helpful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few degrees with a regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([x_sample]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_models = [LinearRegression(), Ridge(alpha=10), Lasso(alpha=10)]\n",
    "\n",
    "scores = [analyze_performance(my_model) for my_model in test_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 4))\n",
    "for no, score in enumerate(scores):\n",
    "    s, name = pd.DataFrame(score), test_models[no].__class__.__name__\n",
    "    f = s.plot(ylim=(-.05,1.05), ax=axes[no], legend=False)\n",
    "    f = axes[no].set_title(\"%s\\nBest cv performance at degree %d\" % (name, s.cv.argmax()))\n",
    "    f = axes[no].set_xlabel('degree'), axes[no].set_ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try a few different values for $\\alpha$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(18, 6))\n",
    "for col, alpha in enumerate([0, 1, 10, 100]):\n",
    "    scores = [analyze_performance(my_model) for my_model in [Ridge(alpha=alpha), Lasso(alpha=alpha)]]\n",
    "    for row, score in enumerate(scores):\n",
    "        s, name = pd.DataFrame(score), test_models[row].__class__.__name__\n",
    "        f = s.plot(ylim=(-.05,1.05), ax=axes[row, col], legend=False)\n",
    "        f = axes[row, col].set_title(\"%s (alpha %d)\\nBest cv at degree %d\" % (name, alpha, s.cv.argmax()))\n",
    "        f = axes[row, col].set_xlabel('degree'), axes[row, col].set_ylabel('$R^2$')\n",
    "f = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that that Ridge and Lasso keep performing well for higher degrees, because of their regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Not verified yet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Take a dataset from the previous Linear Regression notebook (eg Princeton salaries or Boston house prices) and try to repeat the exercises using regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "```Python\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "model.fit(X,y)\n",
    "\n",
    "print model.coef_\n",
    "print model.alpha_\n",
    "```\n",
    "\n",
    "### Additional Resources\n",
    "- [Linear Regression with Python](http://connor-johnson.com/2014/02/18/linear-regression-with-python/)\n",
    "- [Statsmodels Documentation](http://statsmodels.sourceforge.net/stable/index.html)\n",
    "- [Python 538 Model](https://github.com/jseabold/538model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
